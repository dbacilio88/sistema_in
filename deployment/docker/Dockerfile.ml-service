# Dockerfile para ML Service
FROM python:3.11-slim

# Configurar variables de entorno
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Instalar dependencias del sistema
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgl1-mesa-glx \
    && rm -rf /var/lib/apt/lists/*

# Crear directorio de trabajo
WORKDIR /app

# Copiar requirements y instalar dependencias Python
COPY ml-service/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Instalar PyTorch optimizado para CPU
RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# Copiar código de la aplicación
COPY ml-service/ .

# Crear usuario no-root para seguridad
RUN adduser --disabled-password --gecos '' mluser && \
    chown -R mluser:mluser /app
USER mluser

# Crear directorios necesarios
RUN mkdir -p /app/models /app/temp /app/logs

# Descargar modelos base (esto se puede hacer en un init container)
# RUN python download_models.py

# Exponer puerto
EXPOSE 8001

# Health check
HEALTHCHECK --interval=30s --timeout=60s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:8001/health || exit 1

# Comando por defecto
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8001", "--workers", "2"]