# Gu√≠a de Verificaci√≥n y Testing - Integraci√≥n ML

## Estado Actual

‚úÖ **C√≥digo completado**: Toda la integraci√≥n de YOLOv8, EasyOCR y Django API est√° implementada  
üîÑ **Build en progreso**: El servicio de inferencia se est√° reconstruyendo con las nuevas dependencias  
‚ö†Ô∏è **Error detectado y corregido**: Problema en la carga del modelo YOLO (l√≠nea de export removida)

## Pasos para Verificar

### 1. Verificar que el servicio est√° corriendo

```bash
cd /home/bacsystem/github.com/sistema_in
docker compose ps inference
```

**Esperado**: El contenedor debe estar en estado "Up" o "Running"

### 2. Verificar logs de inicializaci√≥n

```bash
docker compose logs inference | grep -E "(Initializing|initialized|YOLO|OCR|ML models)"
```

**Esperado**:
```
INFO: Initializing ML models...
INFO: YOLO model loaded from /app/models/yolov8n.pt
INFO: OCR reader loaded for languages: ['en']
INFO: ML models initialized successfully
INFO: Application startup complete.
```

### 3. Buscar errores

```bash
docker compose logs inference | grep -i error | tail -20
```

**Si hay errores**, revisar:
- Error de "Invalid export format": Ya fue corregido, rebuild necesario
- Error de memoria: Puede ocurrir si no hay suficiente RAM (YOLOv8n + EasyOCR ~ 2GB)
- Error de torch/CUDA: Normal si no hay GPU, debe funcionar en CPU

### 4. Verificar que el modelo se descarg√≥

```bash
docker exec -it traffic-inference ls -lh /app/models/
```

**Esperado**:
```
-rw-r--r-- 1 appuser appuser 6.2M Nov  2 07:29 yolov8n.pt
```

### 5. Probar el endpoint WebSocket

Desde el navegador, abrir la consola de desarrollador (F12) y ejecutar:

```javascript
const ws = new WebSocket('ws://localhost:8001/api/ws/inference');

ws.onopen = () => {
    console.log('‚úÖ WebSocket conectado');
    
    // Enviar configuraci√≥n
    ws.send(JSON.stringify({
        type: 'config',
        data: {
            detection_types: ['speed'],
            confidence_threshold: 0.7,
            enable_ocr: true,
            enable_speed_detection: true,
            speed_limit: 60
        }
    }));
};

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    console.log('üì© Mensaje recibido:', data);
};

ws.onerror = (error) => {
    console.error('‚ùå Error:', error);
};

ws.onclose = () => {
    console.log('üîå WebSocket cerrado');
};
```

### 6. Probar desde el Frontend

1. **Abrir la aplicaci√≥n**:
   - URL: http://localhost:3002
   - Navegar a: "Monitoreo en Tiempo Real"

2. **Configurar detecci√≥n**:
   - Seleccionar: "C√°mara Web Local"
   - Establecer l√≠mite de velocidad: 60 km/h
   - Habilitar: Detecci√≥n de velocidad, OCR
   - Tipos de infracciones: Exceso de velocidad

3. **Iniciar detecci√≥n**:
   - Click en "Iniciar Detecci√≥n"
   - Permitir acceso a la c√°mara
   - Observar el video con overlays de detecci√≥n

4. **Verificar detecciones en tiempo real**:
   - Debe mostrar bounding boxes alrededor de veh√≠culos
   - Si detecta una placa, debe mostrar el texto
   - Si estima velocidad, debe mostrar km/h

### 7. Verificar registro en Base de Datos

```bash
# Acceder al admin de Django
# URL: http://localhost:8000/admin
# Usuario: admin (o el que hayas creado)
# Ir a: Infractions ‚Üí Infractions
```

**O usar la API**:

```bash
# Listar infracciones
curl http://localhost:8000/api/infractions/ | jq

# Buscar por estado pending
curl "http://localhost:8000/api/infractions/?status=pending" | jq

# Buscar por placa
curl "http://localhost:8000/api/infractions/?search=ABC-123" | jq
```

## Soluci√≥n de Problemas

### Problema: "YOLO model not found"

**Soluci√≥n**: El modelo se descarga autom√°ticamente en el primer inicio. Espera 10-30 segundos.

```bash
# Verificar si est√° descargando
docker compose logs -f inference | grep -i downloading
```

### Problema: "Out of memory" o servicio se reinicia

**Causa**: YOLOv8 + EasyOCR requieren ~2GB RAM

**Soluci√≥n**:
1. Aumentar memoria de Docker Desktop (Settings ‚Üí Resources ‚Üí Memory: 4GB+)
2. O deshabilitar OCR temporalmente:
   ```bash
   # En inference-service/app/core/config.py
   OCR_GPU = False  # Ya est√° as√≠
   # Y comentar la inicializaci√≥n de OCR en model_service.py
   ```

### Problema: "Failed to connect to Django"

**Verificar que Django est√© corriendo**:

```bash
docker compose ps django

# Debe mostrar: Up (healthy)
```

**Probar conectividad**:

```bash
docker exec -it traffic-inference curl http://django:8000/api/infractions/
```

**Esperado**: JSON con lista de infracciones (puede estar vac√≠a: `[]`)

### Problema: OCR no detecta placas

**Causas comunes**:
1. Iluminaci√≥n insuficiente ‚Üí Mejorar luz de la habitaci√≥n
2. C√°mara muy lejos ‚Üí Acercarse al objeto
3. Placa no en formato Per√∫ ‚Üí Solo detecta: AAA-123, AB-1234, A12-345
4. Confianza muy baja ‚Üí El c√≥digo ya filtra < 0.5

**Debug**:
```bash
# Ver logs de OCR
docker compose logs inference | grep -i ocr
```

### Problema: Velocidad siempre 0 o incorrecta

**Causa**: Necesita calibraci√≥n de c√°mara

**Soluci√≥n temporal**: El sistema usa tracking simple, requiere:
- M√≠nimo 10 frames de historial
- Veh√≠culo movi√©ndose (no est√°tico)
- Calibraci√≥n correcta de `meters_per_pixel`

**Para MVP**: La detecci√≥n de velocidad es aproximada. Para producci√≥n implementar Optical Flow.

## Prueba Manual Completa

### Escenario 1: Detecci√≥n B√°sica de Veh√≠culos

1. Abrir http://localhost:3002 ‚Üí "Monitoreo en Tiempo Real"
2. Seleccionar "C√°mara Web Local"
3. Configurar:
   - L√≠mite velocidad: 60 km/h
   - Umbral confianza: 0.7
   - Solo habilitar "Exceso de velocidad"
4. Iniciar detecci√≥n
5. Mover un objeto grande frente a la c√°mara (como un coche de juguete)
6. **Esperado**: Debe dibujar un bounding box si lo detecta como veh√≠culo

### Escenario 2: OCR de Placas (Simulaci√≥n)

**Nota**: Para testing real de OCR, necesitas una imagen de placa peruana impresa

1. Imprimir o mostrar en pantalla una placa: `ABC-123`
2. Configurar:
   - Habilitar OCR
   - Mostrar en el video frente a la c√°mara
3. **Esperado**: Si la detecta como veh√≠culo y lee la placa, debe mostrar el texto

### Escenario 3: Verificar Registro en BD

1. Realizar detecciones durante 1-2 minutos
2. Abrir Django Admin: http://localhost:8000/admin
3. Navegar a: Infractions
4. **Esperado**: 
   - Ver infracciones creadas autom√°ticamente
   - Cada una con:
     - C√≥digo: `INF-SPE-{timestamp}`
     - Tipo: speed
     - Veh√≠culo asociado
     - Velocidad detectada y l√≠mite
     - Metadata con bbox y confianza

## Comandos √ötiles

```bash
# Rebuild completo del servicio
docker compose build --no-cache inference
docker compose up -d inference

# Ver logs en tiempo real
docker compose logs -f inference

# Reiniciar todos los servicios
docker compose restart

# Ver estado de todos los contenedores
docker compose ps

# Entrar al contenedor de inferencia
docker exec -it traffic-inference bash

# Verificar instalaci√≥n de paquetes
docker exec -it traffic-inference pip list | grep -E "(ultralytics|easyocr|torch)"

# Ver uso de recursos
docker stats traffic-inference

# Limpiar y reconstruir todo
docker compose down
docker compose build
docker compose up -d
```

## Logs Esperados (Sin Errores)

```
traffic-inference  | INFO:     Starting Traffic Inference Service v1.0.0
traffic-inference  | {"event": "Initializing ML models...", "level": "info"}
traffic-inference  | {"event": "YOLO model not found, downloading...", "level": "info"}
traffic-inference  | Downloading yolov8n.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:01<00:00, 5.2MB/s]
traffic-inference  | {"event": "YOLO model loaded from /app/models/yolov8n.pt", "level": "info"}
traffic-inference  | {"event": "OCR reader loaded for languages: ['en']", "level": "info"}
traffic-inference  | {"event": "ML models initialized successfully", "level": "info"}
traffic-inference  | INFO:     Application startup complete.
traffic-inference  | INFO:     Uvicorn running on http://0.0.0.0:8001
```

## Siguiente Fase: Optimizaci√≥n

Una vez verificado que funciona:

### 1. Calibraci√≥n de C√°mara
- Medir distancia real vs p√≠xeles
- Actualizar `CAMERA_CALIBRATION` en config.py

### 2. Fine-tuning de Umbrales
- Ajustar `YOLO_CONFIDENCE_THRESHOLD` seg√∫n false positives
- Ajustar m√≠nimo de OCR confidence

### 3. Entrenamiento Custom (Opcional)
- Recopilar dataset local (veh√≠culos y placas peruanas)
- Fine-tune YOLOv8 con `yolo train`
- Fine-tune EasyOCR con dataset de placas

### 4. Integraci√≥n de Modelos Adicionales
- Detecci√≥n de sem√°foros (traffic_light.pt)
- Segmentaci√≥n de carriles (lane_detection.pt)
- Clasificaci√≥n de color de veh√≠culo

### 5. Mejoras de Rendimiento
- Activar GPU si est√° disponible
- Implementar batch processing
- Optimizar con TensorRT/ONNX

---

**Documentaci√≥n Completa**:
- `docs/ML_INTEGRATION.md` - Detalles t√©cnicos de la integraci√≥n
- `docs/INTEGRATION_SUMMARY.md` - Resumen de cambios realizados
- Este archivo - Gu√≠a de verificaci√≥n y testing

